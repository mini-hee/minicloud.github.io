---
title: 빅데이터 수집2 - Kafka
author: mini
date: 2023-08-07 11:50:00 +0800
categories: [Data, Data Engineering]
tags: [data engineering, flume]
toc : true
---

## Kafka란
MOM(Message Oriented Middleware) 소프트웨어 중 하나로 대규모로 발생하는 메시지성 데이터를 비동기 방식으로 중
재

### 역할
플럼이 실시간으로 데이터를 수집해 카프카 토픽에 전송하면 카프카는 토픽에 임시저장하고 있다가 컨슈머 프로그램이 작동하면 토픽에서 데이터를 가져간다.

최종 목적지의 에러로 플럼의 체널에 데이터들이 쌓이게 되면 플럼의 장애로 이어진다. 이를 방지하기위해 중간에 안정적인 버퍼링 처리를 해줌으로써 안정적인 수집 아키텍처를 구성할 수 있다.


### 1. 설치
```
sudo wget https://archive.apache.org/dist/kafka/3.2.1/kafka_2.13-3.2.1.tgz
sudo tar -xzvf kafka_2.13-3.2.1.tgz -C /usr/local
sudo mv kafka_2.13-3.2.1/ kafka
```

### 2.설정
1. ~/.bashrc
```
export KAFKA_HOME=/usr/local/kafka
export KAFKA_HEAP_OPTS="-Xmx512m -Xms512m"
```
-Xms :힙의 초기 크기(최소량)
-Xmx :힙의 최대 크기

2. 소유권 변경
```
sudo chown -R $USER:$USER /usr/local/kafka
```
3. server.config 수정
```
# 주석제거
listners=PLAINTEXT://:9092
advertised.listeners PLAINTEXT://server01:9092
# 여러 호스트로 분산처리 할 경우
zookeeper.connect=server01:2181,server02:2181
```

### 3.실행
※ ZOOKEEPER 실행 후
```
$KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties --daemon
```

확인
```
$ZOOKEEPER/bin/zkCli.sh
ls /
# kafka 확인
```


### 4. Topic 생성
```
./kafka-topics.sh --create --bootstrap-server nn2:9092 --replication-factor 1 --partitions 1 --topic SmartCar-Topic
```

### Kafka producer - consumer 사용
```
$KAFKA_HOME/bin/kafka-console-producer.sh --broker-list nn2:9092 -topic SmartCar-Topic
$KAFKA_HOME/bin/kafka-console-consumer.sh -bootstrap-server nn2:9092 --topic SmartCar-Topic --partition 0 --from-beginning
```

결과화면
![kafka-test](/assets/img/posts/kafka-test.png)

<br/><br/>



---------------------------------------------
출처 및 참고자료<br/>
⌜실무로 배우는 빅데이터 기술⌟<br/>
[youtube-빅공잼-kafka 클러스터 환경구축](https://www.youtube.com/watch?v=WUryWzl5phs&t=8s)


